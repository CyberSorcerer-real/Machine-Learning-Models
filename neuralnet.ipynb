{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34944edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from planar_utils import (\n",
    "    plot_decision_boundary,\n",
    "    sigmoid,\n",
    "    load_planar_dataset,\n",
    "    load_extra_datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c6f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_planar_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84f30d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (2, 400)\n",
      "The shape of Y is: (1, 400)\n",
      "I have m = 400 training examples!\n"
     ]
    }
   ],
   "source": [
    "shape_X = X.shape\n",
    "shape_Y = Y.shape\n",
    "m = shape_X[1] \n",
    "\n",
    "print(\"The shape of X is: \" + str(shape_X))\n",
    "print(\"The shape of Y is: \" + str(shape_Y))\n",
    "print(\"I have m = %d training examples!\" % (m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e12d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_size(X,Y):\n",
    "\n",
    "    n_x = X.shape[0]\n",
    "    n_y = Y.shape[0]\n",
    "    n_h = 4\n",
    "    return n_x, n_h, n_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0e063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_parameters(n_x,n_h,n_y):\n",
    "\n",
    "\n",
    "    scaling_factor=0.01\n",
    "    w1 = np.random.randn(n_h,n_x)*scaling_factor\n",
    "    w2 = np.random.randn(n_y,n_h)*scaling_factor\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    b2 = np.zeros((n_y,1))\n",
    "\n",
    "    parameters = { \"w1\" : w1 , \"w2\": w2 , \"b1\" : b1, \"b2\" : b2  }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05009db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x, n_h, n_y = layer_size(X, Y)\n",
    "parameters = define_parameters(n_x, n_h, n_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e97588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d595e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, parameters):\n",
    "\n",
    "    w1 = parameters.get(\"w1\")\n",
    "    b1 = parameters.get(\"b1\")\n",
    "    w2 = parameters.get(\"w2\")\n",
    "    b2 = parameters.get(\"b2\")\n",
    "\n",
    "    Z1 = np.dot(w1,X)+b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(w2,A1)+b2\n",
    "    A2 = 1 / (1 + np.exp(-Z2))\n",
    "\n",
    "    cache = {\"Z1\" : Z1 , \"A1\" : A1 , \"Z2\" : Z2 , \"A2\" : A2}\n",
    "\n",
    "    return A2 ,cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbfb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "   \n",
    "    m = Y.shape[1] \n",
    "\n",
    "    \n",
    "    logprobs = np.multiply(np.log(A2), Y) + np.multiply((1 - Y), np.log(1 - A2))\n",
    "    cost = (-1 / m) * np.sum(logprobs)\n",
    "    \n",
    "\n",
    "    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect.\n",
    "    \n",
    "    assert isinstance(cost, float)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "342166f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Back_prop(X , Y , cache , parameters):\n",
    "\n",
    "    w1 = parameters.get(\"w1\")\n",
    "    b1 = parameters.get(\"b1\")\n",
    "    w2 = parameters.get(\"w2\")\n",
    "    b2 = parameters.get(\"b2\")\n",
    "\n",
    "    A2 = cache.get(\"A2\")\n",
    "    A1 = cache.get(\"A1\")\n",
    "    Z1 = cache.get(\"Z1\")\n",
    "    Z2 = cache.get(\"Z2\")\n",
    "\n",
    "    d_Z2 = A2 - Y\n",
    "    d_W2 = (1/m)*np.dot(d_Z2,A1.T)\n",
    "    d_b2 =  (1/m)*np.sum(d_Z2,axis=1, keepdims=True)\n",
    "\n",
    "    d_Z1 = w2.T * d_Z2 * ( 1 - np.power(A1, 2))\n",
    "    d_W1 = (1/m)*np.dot(d_Z1,X.T)\n",
    "    d_b1 = (1/m)*np.sum(d_Z1)\n",
    "\n",
    "    grads = {\"dW1\": d_W1, \"db1\": d_b1, \"dW2\": d_W2, \"db2\": d_b2}\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45271c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_para(grads , parameters , learning_rate=1.02):\n",
    "\n",
    "    w1 = parameters.get(\"w1\")\n",
    "    b1 = parameters.get(\"b1\")\n",
    "    w2 = parameters.get(\"w2\")\n",
    "    b2 = parameters.get(\"b2\")\n",
    "\n",
    "    d_W1 = grads.get(\"dW1\")\n",
    "    d_b1 = grads.get(\"db1\")\n",
    "    d_W2 = grads.get(\"dW2\")\n",
    "    d_b2 = grads.get(\"db2\")\n",
    "\n",
    "    w1 -= learning_rate*d_W1\n",
    "    b1 -= learning_rate*d_b1\n",
    "    w2 -= learning_rate*d_W2\n",
    "    b2 -= learning_rate*d_b2\n",
    "\n",
    "    parameters = {\"w1\": w1, \"b1\": b1, \"w2\": w2, \"b2\": b2}\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb7d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X , Y , n_h , parameters , learning_rate=1.02,iterations=10000,  print_cost=False):\n",
    "\n",
    "    n_x = layer_size(X,Y)[0]\n",
    "    n_y = layer_size(X,Y)[2]\n",
    "\n",
    "    w1 = parameters.get(\"w1\")\n",
    "    b1 = parameters.get(\"b1\")\n",
    "    w2 = parameters.get(\"w2\")\n",
    "    b2 = parameters.get(\"b2\")\n",
    "\n",
    "    for i in range(0 , iterations):\n",
    "\n",
    "        A2,cache = forward_prop(X,parameters)\n",
    "\n",
    "        cost = compute_cost(A2,Y,parameters)\n",
    "\n",
    "        grads = Back_prop(X , Y , cache , parameters)\n",
    "\n",
    "        parameters = update_para(grads , parameters , learning_rate=1.02)\n",
    "\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae8e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "\n",
    "    A2, _ = forward_prop(X, parameters)  # unpack tuple\n",
    "    predictions = A2 > 0.5\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8a2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693113\n",
      "Cost after iteration 1000: 0.290080\n",
      "Cost after iteration 2000: 0.276785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 3000: 0.268790\n",
      "Cost after iteration 4000: 0.263289\n",
      "Cost after iteration 5000: 0.259274\n",
      "Cost after iteration 6000: 0.259974\n",
      "Cost after iteration 7000: 0.259560\n",
      "Cost after iteration 8000: 0.226745\n",
      "Cost after iteration 9000: 0.227836\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(X, Y, n_h,parameters,learning_rate=1.02, iterations=10000, print_cost=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc3f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_13820\\3497124417.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  accuracy = float((np.dot(Y, predictions.T) + np.dot(1 - Y, 1 - predictions.T)) / Y.size * 100)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'parameters' is already trained, and 'X' and 'Y' are the dataset\n",
    "predictions = predict(parameters, X)\n",
    "accuracy = float((np.dot(Y, predictions.T) + np.dot(1 - Y, 1 - predictions.T)) / Y.size * 100)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175035a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
